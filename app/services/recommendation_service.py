from typing import List, Dict, Any
import time
from datetime import datetime

from app.models.pre_info import PreInfo
from app.schemas.spot import RecommendSpots
from app.services.llm_service import LLMService
from app.services.google_trends_service import GoogleTrendsService
from app.services.places_service import PlacesService


class RecommendationService:
    """
    ã‚¹ãƒãƒƒãƒˆæ¨è–¦ã‚µãƒ¼ãƒ“ã‚¹
    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã«å¾“ã£ã¦å¤šæ®µéšæ¨è–¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    """

    def __init__(self):
        try:
            print("ğŸš€ RecommendationServiceåˆæœŸåŒ–é–‹å§‹...")

            # LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ¤– LLMServiceåˆæœŸåŒ–ä¸­...")
            self.llm_service = LLMService()
            print("âœ… LLMServiceåˆæœŸåŒ–å®Œäº†")

            # Google Trendsã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ”¥ GoogleTrendsServiceåˆæœŸåŒ–ä¸­...")
            self.google_trends_service = GoogleTrendsService()
            print("âœ… GoogleTrendsServiceåˆæœŸåŒ–å®Œäº†")

            # Placesã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ—ºï¸ PlacesServiceåˆæœŸåŒ–ä¸­...")
            self.places_service = PlacesService()
            print("âœ… PlacesServiceåˆæœŸåŒ–å®Œäº†")

            # TODO: ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ä¾å­˜æ€§æ³¨å…¥
            # self.vector_search_service = vector_search_service
            # self.scoring_service = scoring_service

            print("âœ… RecommendationServiceåˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            print(f"âŒ RecommendationServiceåˆæœŸåŒ–å¤±æ•—: {str(e)}")
            # åˆæœŸåŒ–å¤±æ•—ã—ã¦ã‚‚ã‚µãƒ¼ãƒ“ã‚¹ã¯ç¶™ç¶šå®Ÿè¡Œ
            self.llm_service = None
            self.google_trends_service = None
            self.places_service = None

    async def recommend_spots_from_pre_info(self, pre_info: PreInfo) -> Dict[str, Any]:
        """
        pre_infoã‚’åŸºã«ã‚¹ãƒãƒƒãƒˆæ¨è–¦ã‚’ç”Ÿæˆ

        Args:
            pre_info: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ—…è¡Œäº‹å‰æƒ…å ±

        Returns:
            æ¨è–¦çµæœã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        start_time = time.time()
        processing_metadata = {
            "api_calls_made": 0,
            "total_spots_found": 0,
            "scoring_weights": {},
        }

        try:
            # Step 3-1: LLMã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ + åˆæœŸé‡ã¿ç”Ÿæˆ
            keywords, initial_weights = await self._generate_keywords_and_weights(
                pre_info
            )
            processing_metadata["api_calls_made"] += 1

            # Step 3-2: Google Trendsãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (å®Ÿéš›ã®å®Ÿè£…!)
            hot_keywords = await self._filter_trending_keywords(keywords)
            processing_metadata["api_calls_made"] += len(keywords)

            # Step 3-3: Places Text Search
            place_ids = await self._search_places_by_keywords(hot_keywords, pre_info)
            processing_metadata["api_calls_made"] += len(hot_keywords)

            # Step 3-4: Places Details
            place_details = await self._get_place_details(place_ids)
            processing_metadata["api_calls_made"] += 1
            processing_metadata["total_spots_found"] = len(place_details)

            # Step 3-5: Vector Search (æ„å‘³é¡ä¼¼åº¦)
            vector_candidates = await self._vector_search_similarity(
                pre_info, place_details
            )
            processing_metadata["api_calls_made"] += 1

            # Step 3-6: LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚° + é‡ã¿èª¿æ•´ (80å€‹ â†’ 40å€‹)
            reranked_spots, updated_weights = await self._llm_rerank_and_adjust_weights(
                vector_candidates, initial_weights, pre_info
            )
            processing_metadata["api_calls_made"] += 1
            processing_metadata["scoring_weights"] = updated_weights

            # Step 3-7: æœ€çµ‚ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° (40å€‹ â†’ TOP-N)
            final_recommendations = await self._final_scoring_and_ranking(
                reranked_spots, updated_weights, pre_info
            )

            # å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time_ms = int((time.time() - start_time) * 1000)

            # æœ€çµ‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚°å‡ºåŠ›
            print("ğŸ¯ æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
            print(f"  - Keywords: {keywords}")
            print(f"  - Hot Keywords: {hot_keywords}")
            print(f"  - Weights: {updated_weights}")
            print(f"  - Processing time: {processing_time_ms}ms")
            print(f"  - API calls: {processing_metadata['api_calls_made']}")

            return {
                "rec_spot_id": f"rec_{int(datetime.now().timestamp())}",
                "recommend_spots": final_recommendations,
                "processing_time_ms": processing_time_ms,
                "keywords_generated": keywords,  # ãƒ‡ãƒãƒƒã‚°ç”¨è¿½åŠ 
                "hot_keywords": hot_keywords,  # ãƒˆãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¿½åŠ 
                "initial_weights": initial_weights,  # ãƒ‡ãƒãƒƒã‚°ç”¨è¿½åŠ 
                **processing_metadata,
            }

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚å‡¦ç†æ™‚é–“ã¯è¿”å´
            processing_time_ms = int((time.time() - start_time) * 1000)
            raise Exception(
                f"æ¨è–¦å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)} (å‡¦ç†æ™‚é–“: {processing_time_ms}ms)"
            )

    async def _generate_keywords_and_weights(
        self, pre_info: PreInfo
    ) -> tuple[List[str], Dict[str, float]]:
        """Step 3-1: LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨åˆæœŸé‡ã¿ç”Ÿæˆ"""
        if self.llm_service is None:
            print("âš ï¸ LLMServiceãªã—ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ä½¿ç”¨")
            # ç°¡å˜ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯
            keywords = [
                f"{pre_info.region} è¦³å…‰åœ°",
                f"{pre_info.region} ã‚°ãƒ«ãƒ¡",
                f"{pre_info.region} ã‚«ãƒ•ã‚§",
            ]
            weights = {
                "price": 0.3,
                "rating": 0.4,
                "congestion": 0.2,
                "similarity": 0.1,
            }
            return keywords, weights

        return await self.llm_service.generate_keywords_and_weights(pre_info)

    async def _filter_trending_keywords(self, keywords: List[str]) -> List[str]:
        """Step 3-2: Google Trendsã§äººæ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (å®Ÿéš›ã®å®Ÿè£…!)"""
        if self.google_trends_service is None:
            print("âš ï¸ GoogleTrendsServiceãªã—ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            print(f"ğŸ”¥ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨: {keywords}")
            return keywords

        # å®Ÿéš›ã®Google Trends APIã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        trending_keywords = await self.google_trends_service.filter_trending_keywords(
            keywords, threshold=30  # äººæ°—åº¦30ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿
        )

        print(f"ğŸ”¥ Google Trendsãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {trending_keywords}")
        return trending_keywords

    async def _search_places_by_keywords(
        self, keywords: List[str], pre_info: PreInfo
    ) -> List[str]:
        """Step 3-3: Places Text Searchã§å ´æ‰€IDåé›† (å®Ÿéš›ã®å®Ÿè£…!)"""
        if self.places_service is None:
            print("âš ï¸ PlacesServiceãªã—ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            print(f"ğŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒ€ãƒŸãƒ¼place_idç”Ÿæˆ: {keywords}")
            return [f"fallback_place_{i}" for i in range(20)]

        try:
            all_place_ids = []
            print(f"ğŸ” Places Text Searché–‹å§‹: {len(keywords)}å€‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")

            # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢å®Ÿè¡Œ
            for keyword in keywords:
                place_ids = await self.places_service.text_search(
                    keyword, pre_info.region
                )
                all_place_ids.extend(place_ids)
                print(f"  âœ… '{keyword}': {len(place_ids)}å€‹ç™ºè¦‹")

            # é‡è¤‡å‰Šé™¤
            unique_place_ids = list(set(all_place_ids))
            print(f"ğŸ¯ é‡è¤‡å‰Šé™¤å¾Œ: {len(unique_place_ids)}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯place_id")

            return unique_place_ids

        except Exception as e:
            print(f"âŒ Places Text Searchå¤±æ•—: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return [f"error_place_{i}" for i in range(10)]

    async def _get_place_details(self, place_ids: List[str]) -> List[Dict[str, Any]]:
        """Step 3-4: Places Detailsã§è©³ç´°æƒ…å ±å–å¾— (å®Ÿéš›ã®å®Ÿè£…!)"""
        if self.places_service is None:
            print("âš ï¸ PlacesServiceãªã—ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            print(f"ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒ€ãƒŸãƒ¼è©³ç´°æƒ…å ±ç”Ÿæˆ: {len(place_ids)}å€‹")
            return [
                {
                    "place_id": pid,
                    "name": f"å ´æ‰€_{i+1}",
                    "rating": 4.0 + (i % 5) * 0.2,
                    "address": "ä½æ‰€æƒ…å ±ãªã—",
                    "lat": 35.6762 + (i * 0.01),
                    "lng": 139.6503 + (i * 0.01),
                    "price_level": (i % 4) + 1,
                    "types": ["establishment"],
                }
                for i, pid in enumerate(place_ids[:20])
            ]

        try:
            print(f"ğŸ“ Places Detailsä¸€æ‹¬å–å¾—é–‹å§‹: {len(place_ids)}å€‹")

            # Places APIë¡œ ìƒì„¸ ì •ë³´ ì·¨ë“
            place_details = await self.places_service.get_place_details_batch(place_ids)

            print(f"âœ… Places Detailså–å¾—å®Œäº†: {len(place_details)}å€‹")
            return place_details

        except Exception as e:
            print(f"âŒ Places Detailså–å¾—å¤±æ•—: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return [
                {
                    "place_id": pid,
                    "name": f"ã‚¨ãƒ©ãƒ¼å ´æ‰€_{i+1}",
                    "rating": 3.5,
                    "address": "è©³ç´°æƒ…å ±å–å¾—å¤±æ•—",
                    "lat": 35.6762,
                    "lng": 139.6503,
                    "price_level": 2,
                    "types": ["establishment"],
                }
                for i, pid in enumerate(place_ids[:10])
            ]

    async def _vector_search_similarity(
        self, pre_info: PreInfo, places: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Step 3-5: Vector Searchã§æ„å‘³é¡ä¼¼åº¦è¨ˆç®— (80å€‹å€™è£œ)"""
        # TODO: Vector Searchã‚µãƒ¼ãƒ“ã‚¹å‘¼ã³å‡ºã—
        # return await self.vector_search_service.find_similar_places(pre_info, places, limit=80)

        # ä»®ï¼šä¸Šä½80å€‹é¸æŠ (ã¾ãŸã¯å…¨ä½“ãŒ80å€‹æœªæº€ãªã‚‰å…¨ä½“)
        result = places[:80] if len(places) >= 80 else places
        print(f"ğŸ¯ Vector Searché¡ä¼¼åº¦è¨ˆç®—: {len(result)}å€‹å€™è£œ")
        return result

    async def _llm_rerank_and_adjust_weights(
        self,
        candidates: List[Dict[str, Any]],
        weights: Dict[str, float],
        pre_info: PreInfo,
    ) -> tuple[List[Dict[str, Any]], Dict[str, float]]:
        """Step 3-6: LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚° + é‡ã¿èª¿æ•´ (80å€‹ â†’ 40å€‹)"""
        if self.llm_service is None:
            print("âš ï¸ LLMServiceãªã—ã€‚ã‚·ãƒ³ãƒ—ãƒ«å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½¿ç”¨")
            # ç°¡å˜ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šä¸Šä½40å€‹ + é‡ã¿å¾®èª¿æ•´
            reranked = candidates[:40] if len(candidates) >= 40 else candidates
            adjusted_weights = {**weights, "rating": weights.get("rating", 0.4) + 0.1}
            return reranked, adjusted_weights

        return await self.llm_service.rerank_and_adjust_weights(
            candidates, weights, pre_info
        )

    async def _final_scoring_and_ranking(
        self, spots: List[Dict[str, Any]], weights: Dict[str, float], pre_info: PreInfo
    ) -> List[Dict[str, Any]]:
        """Step 3-7: æœ€çµ‚ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§TOP-Né¸åˆ¥ã¨APIìŠ¤í‚¤ë§ˆ ë³€í™˜"""
        # TODO: Scoringã‚µãƒ¼ãƒ“ã‚¹å‘¼ã³å‡ºã—
        # return await self.scoring_service.score_and_rank(spots, weights, pre_info, top_n=10)

        # ä»®ï¼šä¸Šä½10å€‹é¸æŠ
        top_spots = spots[:10] if len(spots) >= 10 else spots
        print(f"ğŸ† æœ€çµ‚ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: {len(top_spots)}å€‹é¸åˆ¥")

        # API ìŠ¤í‚¤ë§ˆì— ë§ê²Œ TimeSlotSpots í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_spots = []

        # ìŠ¤í¬íŠ¸ë“¤ì„ 3ê°œ ì‹œê°„ëŒ€ë¡œ ë¶„ë°° (ë‹¨ìˆœ ë¶„ë°°)
        spots_per_slot = len(top_spots) // 3 + (1 if len(top_spots) % 3 > 0 else 0)

        time_slots = ["åˆå‰", "åˆå¾Œ", "å¤œ"]
        for i, time_slot in enumerate(time_slots):
            start_idx = i * spots_per_slot
            end_idx = min((i + 1) * spots_per_slot, len(top_spots))
            slot_spots = top_spots[start_idx:end_idx]

            if slot_spots:  # í•´ë‹¹ ì‹œê°„ëŒ€ì— ìŠ¤í¬íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                formatted_spots.append(
                    {
                        "time_slot": time_slot,
                        "spots": [
                            self._convert_to_spot_schema(spot, idx)
                            for idx, spot in enumerate(slot_spots)
                        ],
                    }
                )

        print(f"ğŸ“‹ ì‹œê°„ëŒ€ë³„ ë¶„ë°° ì™„ë£Œ: {len(formatted_spots)}ê°œ ì‹œê°„ëŒ€")
        return formatted_spots

    def _convert_to_spot_schema(
        self, place_data: Dict[str, Any], index: int
    ) -> Dict[str, Any]:
        """Places API ë°ì´í„°ë¥¼ Spot ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜"""
        # ê¸°ë³¸ ì˜ì—…ì‹œê°„ ìƒì„± (ì‹¤ì œë¡œëŠ” opening_hours íŒŒì‹± í•„ìš”)
        business_hours = {
            "MONDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "TUESDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "WEDNESDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "THURSDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "FRIDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "SATURDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "SUNDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
            "HOLIDAY": {"open_time": "09:00:00", "close_time": "18:00:00"},
        }

        # ê¸°ë³¸ í˜¼ì¡ë„ ë°ì´í„° (0-23ì‹œê°„)
        congestion = [30 + (i * 5) % 70 for i in range(24)]  # ì‹œê°„ë³„ í˜¼ì¡ë„ ëª¨ì˜

        return {
            "spot_id": place_data.get("place_id", f"spot_{index}"),
            "longitude": place_data.get("lng", 0.0),
            "latitude": place_data.get("lat", 0.0),
            "recommendation_reason": f"{place_data.get('name', 'ì¥ì†Œ')}ëŠ” í‰ì  {place_data.get('rating', 0.0)}ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.",
            "details": {
                "name": place_data.get("name", f"ì¥ì†Œ_{index}"),
                "congestion": congestion,
                "business_hours": business_hours,
                "price": place_data.get("price_level", 2)
                * 1000,  # price_levelì„ ì›í™”ë¡œ ë³€í™˜
            },
            "selected": False,
        }
