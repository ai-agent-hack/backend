from typing import List, Dict, Any, Optional
import time
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor
import hashlib
import json
import logging

from app.models.pre_info import PreInfo
from app.schemas.spot import RecommendSpots
from app.services.llm_service import LLMService
from app.services.google_trends_service import GoogleTrendsService
from app.services.places_service import PlacesService
from app.services.vector_search_service import VectorSearchService
from app.services.scoring_service import ScoringService

# Initialize module-level logger
logger = logging.getLogger(__name__)


class RecommendationService:
    """
    ã‚¹ãƒãƒƒãƒˆæ¨è–¦ã‚µãƒ¼ãƒ“ã‚¹
    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã«å¾“ã£ã¦å¤šæ®µéšæ¨è–¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    """

    def __init__(self):
        try:
            print("ğŸš€ RecommendationServiceåˆæœŸåŒ–é–‹å§‹...")

            # LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ¤– LLMServiceåˆæœŸåŒ–ä¸­...")
            self.llm_service = LLMService()
            print("âœ… LLMServiceåˆæœŸåŒ–å®Œäº†")

            # Google Trendsã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ”¥ GoogleTrendsServiceåˆæœŸåŒ–ä¸­...")
            self.google_trends_service = GoogleTrendsService()
            print("âœ… GoogleTrendsServiceåˆæœŸåŒ–å®Œäº†")

            # Placesã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ—ºï¸ PlacesServiceåˆæœŸåŒ–ä¸­...")
            self.places_service = PlacesService()
            print("âœ… PlacesServiceåˆæœŸåŒ–å®Œäº†")

            # Vector Searchã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ¯ VectorSearchServiceåˆæœŸåŒ–ä¸­...")
            self.vector_search_service = VectorSearchService()
            print("âœ… VectorSearchServiceåˆæœŸåŒ–å®Œäº†")

            # Scoringã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("ğŸ† ScoringServiceåˆæœŸåŒ–ä¸­...")
            self.scoring_service = ScoringService()
            print("âœ… ScoringServiceåˆæœŸåŒ–å®Œäº†")

            # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì •
            self._cache = {}  # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ
            self._executor = ThreadPoolExecutor(max_workers=8)  # ë” ë§ì€ ì›Œì»¤
            self._cache_ttl = 3600  # 1ì‹œê°„ ìºì‹œ TTL

            # ê°•í™”ëœ ë°°ì¹˜ ì„¤ì • (í‚¤ì›Œë“œ ì¦ê°€ë¡œ ì •í™•ë„ í–¥ìƒ)
            self._max_keywords = 8  # 3ê°œ â†’ 8ê°œë¡œ ì¦ê°€ (ì •í™•ë„ í–¥ìƒ)
            self._places_per_keyword = 12  # í‚¤ì›Œë“œë‹¹ ë” ë§ì€ ê²°ê³¼
            self._vector_limit = 80  # 50ê°œ â†’ 80ê°œë¡œ ë³µì›
            self._final_limit = 30  # 24ê°œ â†’ 30ê°œë¡œ ì¦ê°€
            self._batch_size = 50  # ë” í° ë°°ì¹˜ í¬ê¸°

            print("âœ… RecommendationServiceåˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            print(f"âŒ RecommendationServiceåˆæœŸåŒ–å¤±æ•—: {str(e)}")
            # åˆæœŸåŒ–å¤±æ•—ã—ã¦ã‚‚ã‚µãƒ¼ãƒ“ã‚¹ã¯ç¶™ç¶šå®Ÿè¡Œ
            self.llm_service = None
            self.google_trends_service = None
            self.places_service = None
            self.vector_search_service = None
            self.scoring_service = None

    def _get_cache_key(self, pre_info: PreInfo) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        cache_data = {
            "region": pre_info.region,
            "atmosphere": pre_info.atmosphere,
            "budget": pre_info.budget,
            "participants_count": pre_info.participants_count,
        }
        cache_string = json.dumps(cache_data, sort_keys=True)
        return hashlib.md5(cache_string.encode()).hexdigest()

    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                print(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                return cached_data
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self._cache[cache_key]
                print(f"ğŸ—‘ï¸ ë§Œë£Œëœ ìºì‹œ ì‚­ì œ: {cache_key[:8]}...")
        return None

    def _save_to_cache(self, cache_key: str, data: Dict[str, Any]) -> None:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        self._cache[cache_key] = (data, time.time())
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥: {cache_key[:8]}...")

        # ìºì‹œ í¬ê¸° ê´€ë¦¬ (ìµœëŒ€ 100ê°œ)
        if len(self._cache) > 100:
            # ê°€ì¥ ì˜¤ë˜ëœ ìºì‹œ 1ê°œ ì‚­ì œ
            oldest_key = min(self._cache.keys(), key=lambda k: self._cache[k][1])
            del self._cache[oldest_key]
            print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ: {oldest_key[:8]}...")

    async def recommend_spots_from_pre_info(self, pre_info: PreInfo) -> Dict[str, Any]:
        """
        ê·¹ë„ë¡œ ìµœì í™”ëœ ì¶”ì²œ ì‹œìŠ¤í…œ (ë³‘ë ¬ + ë°°ì¹˜ ìµœì í™”)
        """
        start_time = time.time()

        # ìºì‹œ í‚¤ ìƒì„± ë° ì¡°íšŒ
        cache_key = self._get_cache_key(pre_info)
        cached_result = self._get_from_cache(cache_key)

        if cached_result:
            cache_time_ms = int((time.time() - start_time) * 1000)
            cached_result["processing_time_ms"] = cache_time_ms
            cached_result["from_cache"] = True
            print(f"âš¡ ìºì‹œ íˆíŠ¸ - ì¦‰ì‹œ ë°˜í™˜: {cache_time_ms}ms")
            return cached_result

        # ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        processing_metadata = {
            "total_spots_found": 0,
            "api_calls_made": 0,
            "super_optimization_applied": True,
            "processing_steps": [],
            "from_cache": False,
        }

        try:
            print("ğŸš€ SUPER ìµœì í™” ëª¨ë“œ ì‹œì‘!")

            # ğŸ”¥ MEGA PHASE: ëª¨ë“  ì‘ì—…ì„ ìµœëŒ€í•œ ë³‘ë ¬ë¡œ
            mega_start = time.time()

            # ë™ì‹œ ì‹¤í–‰í•  ì‘ì—…ë“¤
            tasks = []

            # Task 1: LLM í‚¤ì›Œë“œ ìƒì„± (ë¹„ë™ê¸°)
            keywords_task = self._generate_keywords_optimized(pre_info)
            tasks.append(("keywords", keywords_task))

            # Task 2: ê¸°ë³¸ Places ê²€ìƒ‰ (ë³‘ë ¬ ì¤€ë¹„)
            basic_search_task = self._prepare_basic_search(pre_info)
            tasks.append(("basic_search", basic_search_task))

            # Task 3: Vector ëª¨ë¸ ì¤€ë¹„ (ë°±ê·¸ë¼ìš´ë“œ)
            vector_prep_task = self._prepare_vector_service()
            tasks.append(("vector_prep", vector_prep_task))

            print(f"ğŸ”¥ {len(tasks)}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...")

            # ëª¨ë“  ì‘ì—… ë™ì‹œ ì‹¤í–‰
            results = await asyncio.gather(
                *[task[1] for task in tasks], return_exceptions=True
            )

            # ê²°ê³¼ ì •ë¦¬
            keywords = (
                results[0]
                if not isinstance(results[0], Exception)
                else ["ë°”ë¥´ì…€ë¡œë‚˜ ì¡°ìš©í•œ ì¥ì†Œ", "ë°”ë¥´ì…€ë¡œë‚˜ ê³µì›", "ë°”ë¥´ì…€ë¡œë‚˜ ìˆ˜ë„ì›"]
            )
            basic_places = results[1] if not isinstance(results[1], Exception) else []
            vector_ready = results[2] if not isinstance(results[2], Exception) else True

            mega_phase1_time = (time.time() - mega_start) * 1000
            processing_metadata["processing_steps"].append(
                f"MegaPhase1: {mega_phase1_time:.0f}ms"
            )
            print(f"âœ… MEGA PHASE 1 ì™„ë£Œ: {mega_phase1_time:.0f}ms")

            # ğŸš€ MEGA PHASE 2: Places API í­ë°œì  ë³‘ë ¬ ì²˜ë¦¬
            phase2_start = time.time()

            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ + ê¸°ë³¸ ê²€ìƒ‰ ê²°í•©
            all_search_tasks = []

            # í‚¤ì›Œë“œë³„ ë³‘ë ¬ ê²€ìƒ‰ (ìµœì í™”ëœ ë²„ì „ ì‚¬ìš©)
            for keyword in keywords[: self._max_keywords]:
                if self.places_service:
                    search_task = self.places_service.text_search_optimized(
                        keyword, pre_info.region, max_results=60
                    )
                    all_search_tasks.append(search_task)

            # ëª¨ë“  ê²€ìƒ‰ ë™ì‹œ ì‹¤í–‰
            if all_search_tasks:
                search_results = await asyncio.gather(
                    *all_search_tasks, return_exceptions=True
                )

                all_place_ids = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set ì‚¬ìš©
                for result in search_results:
                    if not isinstance(result, Exception) and result:
                        all_place_ids.update(result[: self._places_per_keyword])

                place_ids = list(all_place_ids)[: self._batch_size * 2]  # ìµœëŒ€ 60ê°œ
            else:
                place_ids = [f"fallback_place_{i}" for i in range(30)]

            processing_metadata["api_calls_made"] += len(all_search_tasks)

            # ë°°ì¹˜ë³„ Details ê°€ì ¸ì˜¤ê¸° (ìš¸íŠ¸ë¼ ë³‘ë ¬)
            place_details = await self._get_place_details_ultra_optimized(place_ids)
            processing_metadata["api_calls_made"] += len(place_ids)  # ì‹¤ì œ API í˜¸ì¶œ ìˆ˜
            processing_metadata["total_spots_found"] = len(place_details)

            phase2_time = (time.time() - phase2_start) * 1000
            processing_metadata["processing_steps"].append(
                f"MegaPhase2: {phase2_time:.0f}ms"
            )
            print(f"âœ… MEGA PHASE 2 ì™„ë£Œ: {phase2_time:.0f}ms")

            # ğŸ¯ MEGA PHASE 3: Vector + LLM + Scoring ì´ˆë³‘ë ¬ ì²˜ë¦¬
            phase3_start = time.time()

            # ë™ì‹œ ì‹¤í–‰: Vector Search + LLM ì¤€ë¹„
            vector_task = self._vector_search_mega_optimized(pre_info, place_details)

            # Vector Search ì™„ë£Œ í›„ LLM + Scoring ë³‘ë ¬
            vector_candidates = await vector_task
            processing_metadata["api_calls_made"] += 1

            # LLMê³¼ ê¸°ë³¸ ìŠ¤ì½”ì–´ë§ì„ ë™ì‹œì—
            llm_task = self._llm_rerank_ultra_fast(vector_candidates, pre_info)
            basic_scoring_task = self._basic_scoring_parallel(
                vector_candidates, pre_info
            )

            llm_result, basic_scores = await asyncio.gather(
                llm_task, basic_scoring_task, return_exceptions=True
            )

            # ê²°ê³¼ ê²°í•© (LLM ì„±ê³µ ì‹œ ì‚¬ìš©, ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìŠ¤ì½”ì–´ë§)
            if not isinstance(llm_result, Exception):
                final_spots = llm_result[: self._final_limit]
            else:
                final_spots = (
                    basic_scores[: self._final_limit]
                    if not isinstance(basic_scores, Exception)
                    else vector_candidates[: self._final_limit]
                )

            processing_metadata["api_calls_made"] += 1

            phase3_time = (time.time() - phase3_start) * 1000
            processing_metadata["processing_steps"].append(
                f"MegaPhase3: {phase3_time:.0f}ms"
            )
            print(f"âœ… MEGA PHASE 3 ì™„ë£Œ: {phase3_time:.0f}ms")

            # ğŸ† ìµœì¢… ë³€í™˜ (ì´ˆê³ ì†)
            format_start = time.time()
            final_recommendations = self._format_spots_ultra_fast(final_spots)
            format_time = (time.time() - format_start) * 1000
            processing_metadata["processing_steps"].append(
                f"Format: {format_time:.0f}ms"
            )

            # ì´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time_ms = int((time.time() - start_time) * 1000)

            # ì„±ëŠ¥ ë¦¬í¬íŠ¸
            print("ğŸš€ SUPER ìµœì í™” ê²°ê³¼:")
            print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time_ms}ms")
            print(f"  - ë‹¨ê³„ë³„ ì‹œê°„: {processing_metadata['processing_steps']}")
            print(f"  - API í˜¸ì¶œ ìµœì í™”: {processing_metadata['api_calls_made']}íšŒ")
            print(f"  - ì¥ì†Œ ë°œê²¬: {processing_metadata['total_spots_found']}ê°œ")
            print(f"  - ìµœì¢… ì¶”ì²œ: {len(final_recommendations)}ê°œ ì‹œê°„ëŒ€")

            # ì´ˆê¸° ê°€ì¤‘ì¹˜ (ê°„ë‹¨í•œ ê¸°ë³¸ê°’)
            initial_weights = {
                "price": 0.7,
                "rating": 0.5,
                "congestion": 0.8,
                "similarity": 0.9,
            }

            # ìµœì¢… ê²°ê³¼ ìƒì„±
            result = {
                "rec_spot_id": f"rec_{int(datetime.now().timestamp())}",
                "recommend_spots": final_recommendations,
                "processing_time_ms": processing_time_ms,
                "keywords_generated": keywords,
                "hot_keywords": keywords,  # ê°„ì†Œí™”
                "initial_weights": initial_weights,
                **processing_metadata,
            }

            # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            self._save_to_cache(cache_key, result.copy())

            return result

        except Exception as e:
            processing_time_ms = int((time.time() - start_time) * 1000)
            raise Exception(
                f"SUPER ìµœì í™” ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)} (ì²˜ë¦¬ì‹œê°„: {processing_time_ms}ms)"
            )

    async def _generate_keywords_optimized(self, pre_info: PreInfo) -> List[str]:
        """ìµœì í™”ëœ í‚¤ì›Œë“œ ìƒì„± (ê°œìˆ˜ ì¦ê°€ë¡œ ì •í™•ë„ í–¥ìƒ)"""
        if self.llm_service is None:
            return [
                f"{pre_info.region} {pre_info.atmosphere}",
                f"{pre_info.region} ê³µì›",
                f"{pre_info.region} ì¹´í˜",
                f"{pre_info.region} ê´€ê´‘",
                f"{pre_info.region} ê·¸ë£¹",
                f"{pre_info.region} ë¬¸í™”",
                f"{pre_info.region} ìì—°",
                f"{pre_info.region} ì•¼ê²½",
            ]

        try:
            keywords, _ = await self.llm_service.generate_keywords_and_weights(pre_info)
            return keywords[: self._max_keywords]  # 8ê°œ ì‚¬ìš©
        except:
            return [
                f"{pre_info.region} {pre_info.atmosphere}",
                f"{pre_info.region} ëª…ì†Œ",
                f"{pre_info.region} ì¹´í˜",
                f"{pre_info.region} ê´€ê´‘",
                f"{pre_info.region} ë¬¸í™”",
            ]

    async def _prepare_basic_search(self, pre_info: PreInfo) -> List[str]:
        """ê¸°ë³¸ ê²€ìƒ‰ ì¤€ë¹„ (ë°±ê·¸ë¼ìš´ë“œ)"""
        # ì¼ë°˜ì ì¸ ì¥ì†Œ í‚¤ì›Œë“œ
        basic_keywords = [f"{pre_info.region} ê´€ê´‘", f"{pre_info.region} ëª…ì†Œ"]
        return basic_keywords

    async def _prepare_vector_service(self) -> bool:
        """Vector ì„œë¹„ìŠ¤ ì¤€ë¹„"""
        # Vector ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
        return self.vector_search_service is not None

    async def _get_place_details_ultra_optimized(
        self, place_ids: List[str]
    ) -> List[Dict[str, Any]]:
        """ğŸš€ ìš¸íŠ¸ë¼ ìµœì í™”ëœ Places Details (ëŒ€ìš©ëŸ‰ ë³‘ë ¬ ë°°ì¹˜)"""
        if self.places_service is None:
            print("âš ï¸ PlacesService ì—†ìŒ. ìš¸íŠ¸ë¼ Fallback")
            return [
                {
                    "place_id": pid,
                    "name": f"ì¥ì†Œ_{i+1}",
                    "rating": 4.0 + (i % 10) * 0.1,
                    "address": "ì£¼ì†Œ ì •ë³´",
                    "lat": 41.3851 + (i * 0.001),
                    "lng": 2.1734 + (i * 0.001),
                    "price_level": (i % 4) + 1,
                    "types": ["establishment"],
                }
                for i, pid in enumerate(place_ids[:60])  # ë” ë§ì€ fallback
            ]

        try:
            print(f"ğŸš€ ìš¸íŠ¸ë¼ ë°°ì¹˜ Details: {len(place_ids)}ê°œ")

            # ìš¸íŠ¸ë¼ ë°°ì¹˜ ì²˜ë¦¬ (20ê°œì”© ë³‘ë ¬)
            place_details = await self.places_service.get_place_details_ultra_batch(
                place_ids, batch_size=20
            )

            print(f"âœ… ìš¸íŠ¸ë¼ ë°°ì¹˜ Details ì™„ë£Œ: {len(place_details)}ê°œ")
            return place_details[:60]  # ìµœëŒ€ 60ê°œë¡œ í™•ì¥

        except Exception as e:
            print(f"âŒ ìš¸íŠ¸ë¼ ë°°ì¹˜ Details ì‹¤íŒ¨: {str(e)}")
            # ê°„ë‹¨í•œ fallback ë°ì´í„° ë°˜í™˜
            return [
                {
                    "place_id": pid,
                    "name": f"Fallback_ì¥ì†Œ_{i+1}",
                    "rating": 4.0,
                    "address": "ì„ì‹œ ì£¼ì†Œ",
                    "lat": 41.3851 + (i * 0.001),
                    "lng": 2.1734 + (i * 0.001),
                    "price_level": 2,
                    "types": ["establishment"],
                }
                for i, pid in enumerate(place_ids[:30])
            ]

    async def _vector_search_mega_optimized(
        self, pre_info: PreInfo, places: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ë©”ê°€ ìµœì í™”ëœ Vector Search"""
        if self.vector_search_service is None:
            print("âš ï¸ Vector Search ì—†ìŒ. ë¹ ë¥¸ ì„ ë³„")
            return places[: self._vector_limit]

        try:
            # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self._executor,
                lambda: self._vector_search_cpu_intensive(pre_info, places),
            )

            print(f"âœ… ë©”ê°€ Vector Search ì™„ë£Œ: {len(result)}ê°œ")
            return result[: self._vector_limit]
        except Exception as e:
            print(f"âŒ Vector Search ì‹¤íŒ¨: {str(e)}")
            return places[: self._vector_limit]

    def _vector_search_cpu_intensive(self, pre_info, places):
        """CPU ì§‘ì•½ì  Vector Search (ë³„ë„ ìŠ¤ë ˆë“œ)"""
        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” Sentence Transformer ì‚¬ìš©)
        scored_places = []
        query = f"{pre_info.atmosphere} {pre_info.region}"

        for place in places:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜
            name = place.get("name", "")
            score = len(set(query.lower().split()) & set(name.lower().split()))
            place["similarity_score"] = score
            scored_places.append(place)

        # ì ìˆ˜ë³„ ì •ë ¬
        return sorted(
            scored_places, key=lambda x: x.get("similarity_score", 0), reverse=True
        )

    async def _llm_rerank_ultra_fast(
        self, candidates: List[Dict], pre_info: PreInfo
    ) -> List[Dict]:
        """ì´ˆê³ ì† LLM ì¬ë­í‚¹"""
        if self.llm_service is None:
            print("âš ï¸ LLM ì—†ìŒ. ë¹ ë¥¸ ì¬ë­í‚¹")
            return candidates[:40]

        try:
            # LLM ì¬ë­í‚¹ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            reranked, _ = await asyncio.wait_for(
                self.llm_service.rerank_and_adjust_weights(candidates, {}, pre_info),
                timeout=10.0,  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            return reranked[:40]
        except:
            print("âš ï¸ LLM íƒ€ì„ì•„ì›ƒ. ê¸°ë³¸ ì¬ë­í‚¹ ì‚¬ìš©")
            return candidates[:40]

    async def _basic_scoring_parallel(
        self, candidates: List[Dict], pre_info: PreInfo
    ) -> List[Dict]:
        """ë³‘ë ¬ ê¸°ë³¸ ìŠ¤ì½”ì–´ë§ (LLM ë°±ì—…ìš©)"""
        # CPU ì§‘ì•½ì  ìŠ¤ì½”ì–´ë§ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ
        loop = asyncio.get_event_loop()

        try:
            scored = await loop.run_in_executor(
                self._executor,
                lambda: self._calculate_basic_scores(candidates, pre_info),
            )
            return scored[:40]
        except:
            return candidates[:40]

    def _calculate_basic_scores(self, candidates: List[Dict], pre_info) -> List[Dict]:
        """ê¸°ë³¸ ìŠ¤ì½”ì–´ ê³„ì‚° (CPU ì§‘ì•½ì )"""
        for candidate in candidates:
            rating = candidate.get("rating", 3.5)
            price_level = candidate.get("price_level", 2)

            # ê°„ë‹¨í•œ ìŠ¤ì½”ì–´ë§
            rating_score = rating / 5.0
            price_score = 1.0 - (price_level - 1) / 4.0
            final_score = rating_score * 0.6 + price_score * 0.4

            candidate["final_score"] = final_score

        return sorted(candidates, key=lambda x: x.get("final_score", 0), reverse=True)

    def _format_spots_ultra_fast(
        self, spots: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ìŠ¤ë§ˆíŠ¸ ì‹œê°„ëŒ€ë³„ ìŠ¤íŒŸ ë¶„ë°° (í˜¼ì¡ë„ & ì¥ì†Œ íŠ¹ì„± ê¸°ë°˜)"""
        if not spots:
            return []

        # ì‹œê°„ëŒ€ë³„ë¡œ ìŠ¤íŒŸ ë¶„ë¥˜
        categorized_spots = self._categorize_spots_by_time_suitability(spots)

        # ê° ì‹œê°„ëŒ€ë³„ë¡œ í¬ë§·íŒ…
        formatted_spots = []
        for time_slot, slot_spots in categorized_spots.items():
            if slot_spots:
                formatted_spots.append(
                    {
                        "time_slot": time_slot,
                        "spots": [
                            self._convert_to_spot_schema_fast(spot, idx)
                            for idx, spot in enumerate(slot_spots)
                        ],
                    }
                )

        return formatted_spots

    def _categorize_spots_by_time_suitability(
        self, spots: List[Dict[str, Any]]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """í˜¼ì¡ë„ì™€ ì¥ì†Œ íŠ¹ì„±ì— ë”°ë¥¸ ì‹œê°„ëŒ€ë³„ ë¶„ë¥˜"""

        # ì‹œê°„ëŒ€ë³„ ì¹´í…Œê³ ë¦¬
        morning_spots = []
        afternoon_spots = []
        evening_spots = []

        for spot in spots:
            types = spot.get("types", [])
            name = spot.get("name", "").lower()

            # ì¥ì†Œ íŠ¹ì„± ì ìˆ˜ ê³„ì‚°
            morning_score = self._calculate_morning_suitability(spot, types, name)
            afternoon_score = self._calculate_afternoon_suitability(spot, types, name)
            evening_score = self._calculate_evening_suitability(spot, types, name)

            # í˜¼ì¡ë„ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜ (congestion ë°ì´í„° í™œìš©)
            congestion_bonus = self._get_congestion_based_time_bonus(spot)
            morning_score += congestion_bonus.get("morning", 0)
            afternoon_score += congestion_bonus.get("afternoon", 0)
            evening_score += congestion_bonus.get("evening", 0)

            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì‹œê°„ëŒ€ì— ë°°ì •
            max_score = max(morning_score, afternoon_score, evening_score)

            if max_score == morning_score:
                morning_spots.append(spot)
            elif max_score == afternoon_score:
                afternoon_spots.append(spot)
            else:
                evening_spots.append(spot)

        # ê° ì‹œê°„ëŒ€ê°€ ë„ˆë¬´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡ ê· í˜• ì¡°ì •
        morning_spots, afternoon_spots, evening_spots = self._balance_time_slots(
            morning_spots, afternoon_spots, evening_spots
        )

        return {"åˆå‰": morning_spots, "åˆå¾Œ": afternoon_spots, "å¤œ": evening_spots}

    def _calculate_morning_suitability(
        self, spot: Dict, types: List[str], name: str
    ) -> float:
        """ì˜¤ì „ ì í•©ë„ ê³„ì‚°"""
        score = 0.0

        # ì˜¤ì „ì— ì¢‹ì€ ì¥ì†Œ íƒ€ì…ë“¤ (í˜¼ì¡ë„ ê³ ë ¤í•˜ì—¬ ê´€ê´‘ëª…ì†Œë„ í¬í•¨)
        morning_types = {
            "cafe": 3.0,
            "bakery": 2.5,
            "park": 2.5,
            "museum": 2.5,  # ì¡°ìš©í•œ ê´€ëŒ
            "library": 2.0,
            "church": 1.5,
            "temple": 1.5,
            "garden": 2.0,
            "zoo": 1.5,
            "aquarium": 1.5,
            "art_gallery": 2.5,  # ì¡°ìš©í•œ ê´€ëŒ
            # í˜¼ì¡ë„ê°€ ë‚®ì„ ë•Œ ì¢‹ì€ ê´€ê´‘ëª…ì†Œë“¤ ì¶”ê°€
            "tourist_attraction": 1.8,  # ê¸°ë³¸ì€ ë‚®ì§€ë§Œ í˜¼ì¡ë„ ë³´ë„ˆìŠ¤ë¡œ ì—­ì „ ê°€ëŠ¥
            "landmark": 1.5,  # ëœë“œë§ˆí¬ë„ ì˜¤ì „ì´ ëœ í˜¼ì¡
            "viewpoint": 1.8,  # ì „ë§ëŒ€ - ì˜¤ì „ì— ëœ í˜¼ì¡
            "monument": 1.5,  # ê¸°ë…ë¬¼ - ì˜¤ì „ì— ì¡°ìš©í•¨
        }

        # íƒ€ì… ê¸°ë°˜ ì ìˆ˜
        for place_type in types:
            if place_type in morning_types:
                score += morning_types[place_type]

        # typesê°€ ì—†ëŠ” ê²½ìš° ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ê´€ê´‘ëª…ì†Œ ê°ì§€ ë° ë³´ë„ˆìŠ¤ ì ìš©
        if not types:  # types ì •ë³´ê°€ ì—†ì„ ë•Œë§Œ ì´ë¦„ ê¸°ë°˜ ë¶„ë¥˜ ê°•í™”
            tourist_name_patterns = [
                "íƒ€ì›Œ",
                "tower",
                "ì „ë§ëŒ€",
                "observatory",
                "ìŠ¤ì¹´ì´",
                "sky",
                "ë°•ë¬¼ê´€",
                "museum",
                "ë¯¸ìˆ ê´€",
                "gallery",
                "ê¶",
                "palace",
                "ì„±",
                "castle",
                "í•œì˜¥",
                "hanok",
                "ì „í†µ",
                "traditional",
                "ë¬¸í™”ì¬",
                "heritage",
                "ìœ ì ",
                "historic",
                "ëª…ì†Œ",
                "attraction",
                "ê´€ê´‘",
                "tourist",
                "ëœë“œë§ˆí¬",
                "landmark",
                "ë·°",
                "view",
            ]

            tourist_score = 0
            for pattern in tourist_name_patterns:
                if pattern in name:
                    tourist_score = max(tourist_score, 1.8)  # ê´€ê´‘ëª…ì†Œ ê¸°ë³¸ ì ìˆ˜
                    break

            if tourist_score > 0:
                score += tourist_score
                print(f"ê´€ê´‘ëª…ì†Œ ê°ì§€: {name} -> ì˜¤ì „ ê¸°ë³¸ì ìˆ˜ {tourist_score}")

        # ì´ë¦„ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜ (í˜¼ì¡ë„ ë‚®ì€ ê´€ê´‘ëª…ì†Œ í¬í•¨)
        morning_keywords = [
            "ì¹´í˜",
            "cafe",
            "ê³µì›",
            "park",
            "ë°•ë¬¼ê´€",
            "museum",
            "ë¯¸ìˆ ê´€",
            "ê°¤ëŸ¬ë¦¬",
            # ì˜¤ì „ì— í˜¼ì¡ë„ê°€ ë‚®ì•„ì„œ ì¢‹ì€ ê´€ê´‘ëª…ì†Œë“¤
            "ì „ë§ëŒ€",
            "observatory",
            "íƒ€ì›Œ",
            "tower",
            "ì „ë§",
            "view",
            "ì„±",
            "palace",
            "ê¶",
            "ë¬¸í™”ì¬",
            "heritage",
            "ìœ ì ",
            "historic",
            "ì •ì›",
            "garden",
            "ì‚°ì±…ë¡œ",
            "walkway",
            "ë‘˜ë ˆê¸¸",
            "trail",
        ]
        for keyword in morning_keywords:
            if keyword in name:
                score += 1.0

        return score

    def _calculate_afternoon_suitability(
        self, spot: Dict, types: List[str], name: str
    ) -> float:
        """ì˜¤í›„ ì í•©ë„ ê³„ì‚°"""
        score = 0.0

        # ì˜¤í›„ì— ì¢‹ì€ ì¥ì†Œ íƒ€ì…ë“¤
        afternoon_types = {
            "tourist_attraction": 3.0,
            "shopping_mall": 2.5,
            "store": 2.0,
            "amusement_park": 3.0,
            "monument": 2.0,
            "landmark": 2.3,  # ì•½ê°„ ë‚®ì¶¤ (ì €ë… ì•¼ê²½ ê³ ë ¤)
            "stadium": 2.0,
            "university": 1.5,
            "beach": 2.5,
            "hiking_area": 2.0,
            "viewpoint": 2.0,  # ë‚®ì¶¤ (ì•¼ê²½ì€ ì €ë…ì´ ë” ì¢‹ìŒ)
        }

        # íƒ€ì… ê¸°ë°˜ ì ìˆ˜
        for place_type in types:
            if place_type in afternoon_types:
                score += afternoon_types[place_type]

        # ì´ë¦„ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜
        afternoon_keywords = [
            "íƒ€ì›Œ",
            "tower",
            "ì‡¼í•‘",
            "shopping",
            "ê´€ê´‘",
            "ëª…ì†Œ",
            "ëœë“œë§ˆí¬",
        ]
        for keyword in afternoon_keywords:
            if keyword in name:
                score += 1.0

        return score

    def _calculate_evening_suitability(
        self, spot: Dict, types: List[str], name: str
    ) -> float:
        """ì €ë… ì í•©ë„ ê³„ì‚°"""
        score = 0.0

        # ì €ë…ì— ì¢‹ì€ ì¥ì†Œ íƒ€ì…ë“¤
        evening_types = {
            "restaurant": 3.0,
            "bar": 3.0,
            "night_club": 3.0,
            "meal_takeaway": 2.0,
            "food": 2.5,
            "lodging": 1.0,
            "spa": 2.0,
            "movie_theater": 2.5,
            "casino": 3.0,
            "rooftop_bar": 3.0,
            # ì•¼ê²½ ëª…ì†Œë“¤ ì¶”ê°€
            "viewpoint": 2.8,  # ì „ë§ëŒ€ - ì•¼ê²½ ëª…ì†Œ
            "tourist_attraction": 2.3,  # ê´€ê´‘ëª…ì†Œ (ì•¼ê²½ ê³ ë ¤)
            "landmark": 2.5,  # ëœë“œë§ˆí¬ (íƒ€ì›Œ ë“±)
            "bridge": 2.5,  # ë‹¤ë¦¬ (ì•¼ê²½ ëª…ì†Œ)
            "park": 2.0,  # ê³µì› (ì•¼ê²½ ì‚°ì±…)
        }

        # íƒ€ì… ê¸°ë°˜ ì ìˆ˜
        for place_type in types:
            if place_type in evening_types:
                score += evening_types[place_type]

        # ì´ë¦„ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜ (ì•¼ê²½ ëª…ì†Œ ëŒ€í­ ì¶”ê°€)
        evening_keywords = [
            "ë ˆìŠ¤í† ë‘",
            "restaurant",
            "ë°”",
            "bar",
            "í´ëŸ½",
            "club",
            "ë§›ì§‘",
            # ì•¼ê²½ ê´€ë ¨ í‚¤ì›Œë“œë“¤
            "ì•¼ê²½",
            "night view",
            "nightview",
            "ì•¼ê°„",
            "night",
            "íƒ€ì›Œ",
            "tower",
            "ì „ë§ëŒ€",
            "observatory",
            "viewpoint",
            "ë£¨í”„íƒ‘",
            "rooftop",
            "ìŠ¤ì¹´ì´",
            "sky",
            "ë‹¤ë¦¬",
            "bridge",
            "í•œê°•",
            "river",
            "ê°•ë³€",
            "ì „ë§",
            "view",
            "ë·°",
            "íŒŒë…¸ë¼ë§ˆ",
            "panorama",
            "ì¼ëª°",
            "sunset",
            "ì„ì–‘",
            "twilight",
            "í™©í˜¼",
            "ì¡°ëª…",
            "lighting",
            "illumination",
            "ë¼ì´íŠ¸ì—…",
        ]
        for keyword in evening_keywords:
            if keyword in name:
                score += 1.0

        # ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œê°„ ê³ ë ¤ (ì €ë… ëŠ¦ê²Œê¹Œì§€ ìš´ì˜í•˜ëŠ” ê³³)
        business_hours = spot.get("business_hours", {})
        if business_hours:
            # ì£¼ë§ ì €ë… ì‹œê°„ëŒ€ ìš´ì˜ ì—¬ë¶€ í™•ì¸
            saturday_hours = business_hours.get("SATURDAY", {})
            if saturday_hours:
                close_time = saturday_hours.get("close_time", "18:00:00")
                if close_time and close_time >= "20:00:00":  # 8ì‹œ ì´í›„ê¹Œì§€ ìš´ì˜
                    score += 1.5

        # ì•¼ê²½ ëª…ì†Œ íŠ¹ë³„ ë³´ë„ˆìŠ¤ (íƒ€ì›Œ, ì „ë§ëŒ€, ë†’ì€ ê±´ë¬¼)
        if any(
            keyword in name for keyword in ["íƒ€ì›Œ", "tower", "ì „ë§ëŒ€", "ìŠ¤ì¹´ì´", "sky"]
        ):
            score += 2.0  # ì•¼ê²½ ëª…ì†Œ ëŒ€í˜• ë³´ë„ˆìŠ¤

        # ê°•ë³€/ë‹¤ë¦¬ ì•¼ê²½ ë³´ë„ˆìŠ¤
        if any(
            keyword in name for keyword in ["í•œê°•", "ë‹¤ë¦¬", "bridge", "river", "ê°•ë³€"]
        ):
            score += 1.5  # ìˆ˜ë³€ ì•¼ê²½ ë³´ë„ˆìŠ¤

        # ê³µì› ì•¼ê²½ ì‚°ì±… ë³´ë„ˆìŠ¤ (ì €ë… ì‹œê°„ëŒ€ ê³µì›ì€ ì•¼ê²½ ì‚°ì±… ëª©ì )
        if any(park_type in types for park_type in ["park", "garden"]):
            score += 1.0  # ì•¼ê²½ ì‚°ì±… ë³´ë„ˆìŠ¤

        return score

    def _balance_time_slots(
        self, morning: List, afternoon: List, evening: List
    ) -> tuple:
        """ì‹œê°„ëŒ€ë³„ ê· í˜• ì¡°ì • (í•œ ì‹œê°„ëŒ€ê°€ ë„ˆë¬´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡)"""
        total_spots = len(morning) + len(afternoon) + len(evening)

        if total_spots == 0:
            return morning, afternoon, evening

        target_per_slot = total_spots // 3
        min_per_slot = max(1, target_per_slot // 2)  # ìµœì†Œ ë³´ì¥ ê°œìˆ˜

        # ë„ˆë¬´ ì ì€ ì‹œê°„ëŒ€ ì°¾ê¸°
        all_slots = [
            ("morning", morning),
            ("afternoon", afternoon),
            ("evening", evening),
        ]

        # ë¶€ì¡±í•œ ì‹œê°„ëŒ€ì— ë‹¤ë¥¸ ì‹œê°„ëŒ€ì—ì„œ ì´ë™
        for slot_name, slot_spots in all_slots:
            if len(slot_spots) < min_per_slot:
                # ê°€ì¥ ë§ì€ ì‹œê°„ëŒ€ì—ì„œ ì¼ë¶€ ì´ë™
                source_slots = [
                    (name, spots)
                    for name, spots in all_slots
                    if name != slot_name and len(spots) > target_per_slot
                ]

                if source_slots:
                    # ê°€ì¥ ë§ì€ ì‹œê°„ëŒ€ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    source_name, source_spots = max(
                        source_slots, key=lambda x: len(x[1])
                    )
                    needed = min_per_slot - len(slot_spots)
                    available = len(source_spots) - target_per_slot

                    if available > 0:
                        move_count = min(needed, available)
                        moved_spots = source_spots[-move_count:]
                        source_spots = source_spots[:-move_count]
                        slot_spots.extend(moved_spots)

        return morning, afternoon, evening

    def _get_congestion_based_time_bonus(self, spot: Dict) -> Dict[str, float]:
        """í˜¼ì¡ë„ íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì‹œê°„ëŒ€ë³„ ë³´ë„ˆìŠ¤ ì ìˆ˜"""
        bonus = {"morning": 0.0, "afternoon": 0.0, "evening": 0.0}

        # detailsì—ì„œ congestion ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (24ì‹œê°„ í˜¼ì¡ë„ ë°°ì—´)
        details = spot.get("details", {})
        congestion = details.get("congestion", [])

        if not congestion or len(congestion) != 24:
            return bonus

        try:
            # ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ ê³„ì‚°
            morning_congestion = sum(congestion[6:12]) / 6  # 06:00-11:59 ì˜¤ì „
            afternoon_congestion = sum(congestion[12:18]) / 6  # 12:00-17:59 ì˜¤í›„
            evening_congestion = sum(congestion[18:24]) / 6  # 18:00-23:59 ì €ë…

            # í˜¼ì¡ë„ê°€ ë‚®ì€ ì‹œê°„ëŒ€ì— ë³´ë„ˆìŠ¤ (ì¡°ìš©í•œ ì‹œê°„ëŒ€ ì„ í˜¸)
            max_congestion = max(
                morning_congestion, afternoon_congestion, evening_congestion
            )

            if max_congestion > 0:
                # í˜¼ì¡ë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì‹œê°„ëŒ€ì— ê°•ë ¥í•œ ë³´ë„ˆìŠ¤ (ê´€ê´‘ëª…ì†Œ ì—­ì „ ê°€ëŠ¥)
                congestion_diff_morning = (
                    max_congestion - morning_congestion
                ) / max_congestion
                congestion_diff_afternoon = (
                    max_congestion - afternoon_congestion
                ) / max_congestion
                congestion_diff_evening = (
                    max_congestion - evening_congestion
                ) / max_congestion

                # ê´€ê´‘ëª…ì†Œ/ëœë“œë§ˆí¬ëŠ” í˜¼ì¡ë„ ë³´ë„ˆìŠ¤ë¥¼ ë” í¬ê²Œ ì ìš©
                spot_types = spot.get("types", [])
                spot_name = spot.get("details", {}).get("name", "").lower()

                # types ê¸°ë°˜ ë˜ëŠ” ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ê´€ê´‘ëª…ì†Œ ê°ì§€
                is_tourist_spot = any(
                    t in spot_types
                    for t in ["tourist_attraction", "landmark", "viewpoint", "monument"]
                ) or any(
                    keyword in spot_name
                    for keyword in [
                        "íƒ€ì›Œ",
                        "tower",
                        "ì „ë§ëŒ€",
                        "ìŠ¤ì¹´ì´",
                        "sky",
                        "ë°•ë¬¼ê´€",
                        "museum",
                        "ë¯¸ìˆ ê´€",
                        "gallery",
                        "ê¶",
                        "palace",
                        "ëª…ì†Œ",
                        "landmark",
                        "ë·°",
                        "view",
                    ]
                )

                multiplier = (
                    4.0 if is_tourist_spot else 1.5
                )  # ê´€ê´‘ëª…ì†ŒëŠ” í˜¼ì¡ë„ ì˜í–¥ í›¨ì”¬ ë” í¬ê²Œ (ì—­ì „ ê°€ëŠ¥í•˜ë„ë¡)

                bonus["morning"] = congestion_diff_morning * multiplier
                bonus["afternoon"] = congestion_diff_afternoon * multiplier
                bonus["evening"] = congestion_diff_evening * multiplier

                # ë””ë²„ê¹…ìš© ë¡œê·¸
                if is_tourist_spot and congestion_diff_morning > 0.3:
                    print(f"ğŸ›ï¸ ê´€ê´‘ëª…ì†Œ í˜¼ì¡ë„ ë³´ë„ˆìŠ¤: {spot_name}")
                    print(
                        f"   ì˜¤ì „ í˜¼ì¡ë„: {morning_congestion:.1f}, ë³´ë„ˆìŠ¤: {bonus['morning']:.2f}"
                    )
                    print(
                        f"   ì˜¤í›„ í˜¼ì¡ë„: {afternoon_congestion:.1f}, ë³´ë„ˆìŠ¤: {bonus['afternoon']:.2f}"
                    )

            # íŠ¹ë³„ ì¼€ì´ìŠ¤: ìƒˆë²½ì‹œê°„ ìš´ì˜ ì—¬ë¶€ (24ì‹œê°„ ì˜ì—…ì†Œ ë“±)
            late_night_congestion = (
                sum(congestion[22:24] + congestion[0:6]) / 8
            )  # 22:00-05:59
            if late_night_congestion > 10:  # ìƒˆë²½ì—ë„ ì‚¬ëŒì´ ìˆë‹¤ë©´
                bonus["evening"] += 0.5  # ì €ë… ì‹œê°„ëŒ€ ë³´ë„ˆìŠ¤

        except (ZeroDivisionError, IndexError, TypeError):
            # ê³„ì‚° ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            pass

        return bonus

    def _generate_realistic_congestion(
        self, place_data: Dict[str, Any], index: int
    ) -> List[int]:
        """í˜„ì‹¤ì ì¸ í˜¼ì¡ë„ íŒ¨í„´ ìƒì„± (ì¥ì†Œ íƒ€ì…ë³„ ì°¨ë³„í™”)"""
        place_types = place_data.get("types", [])
        name = place_data.get("name", "").lower()

        # ê¸°ë³¸ í˜¼ì¡ë„ íŒ¨í„´ (ì‹œê°„ë³„)
        base_congestion = [
            20,
            15,
            10,
            8,
            10,
            15,
            25,
            35,
            45,
            50,
            55,
            60,
            65,
            70,
            75,
            70,
            65,
            55,
            45,
            40,
            35,
            30,
            25,
            20,
        ]

        # ì¥ì†Œ íƒ€ì…ë³„ íŠ¹ì„±í™”
        if any(
            t in place_types
            for t in ["tourist_attraction", "landmark", "viewpoint", "monument"]
        ):
            # ê´€ê´‘ëª…ì†Œ: ì˜¤ì „(6-11ì‹œ)ì€ ë§¤ìš° í•œì , ì˜¤í›„(12-17ì‹œ)ëŠ” ë§¤ìš° í˜¼ì¡
            tourist_pattern = [
                10,
                8,
                5,
                3,
                5,
                8,
                15,
                20,
                25,
                30,
                35,
                40,
                80,
                90,
                95,
                90,
                85,
                70,
                50,
                40,
                30,
                25,
                20,
            ]
            return [max(5, min(100, val + (index % 10 - 5))) for val in tourist_pattern]

        elif any(t in place_types for t in ["restaurant", "bar", "food"]):
            # ë ˆìŠ¤í† ë‘: ì ì‹¬(11-14ì‹œ), ì €ë…(18-21ì‹œ) í”¼í¬
            restaurant_pattern = [
                5,
                3,
                2,
                2,
                3,
                5,
                10,
                15,
                20,
                25,
                30,
                60,
                80,
                70,
                50,
                40,
                45,
                55,
                85,
                90,
                80,
                60,
                40,
                20,
            ]
            return [
                max(5, min(100, val + (index % 8 - 4))) for val in restaurant_pattern
            ]

        elif any(t in place_types for t in ["cafe", "bakery"]):
            # ì¹´í˜: ì˜¤ì „(8-11ì‹œ), ì˜¤í›„(14-17ì‹œ) í”¼í¬
            cafe_pattern = [
                10,
                8,
                5,
                5,
                8,
                15,
                25,
                50,
                70,
                80,
                75,
                65,
                45,
                40,
                60,
                70,
                65,
                50,
                35,
                25,
                20,
                15,
                12,
                10,
            ]
            return [max(5, min(100, val + (index % 6 - 3))) for val in cafe_pattern]

        elif any(t in place_types for t in ["park", "garden"]):
            # ê³µì›: ì˜¤í›„(15-18ì‹œ), ì €ë… ì‚°ì±…(19-21ì‹œ) í”¼í¬
            park_pattern = [
                5,
                3,
                2,
                2,
                3,
                8,
                15,
                25,
                30,
                35,
                40,
                45,
                50,
                55,
                60,
                70,
                75,
                70,
                65,
                80,
                70,
                50,
                30,
                15,
            ]
            return [max(5, min(100, val + (index % 7 - 3))) for val in park_pattern]

        else:
            # ê¸°íƒ€ ì¥ì†Œ: ê¸°ë³¸ íŒ¨í„´ì— ì•½ê°„ì˜ ë³€í™”
            return [max(5, min(100, val + (index % 12 - 6))) for val in base_congestion]

    def _generate_recommendation_reason(self, place_data: Dict[str, Any]) -> str:
        """å ´æ‰€ã®è©³ç´°æƒ…å ±ã«åŸºã¥ã„ã¦å ´æ‰€ã®èª¬æ˜ã‚’ç”Ÿæˆ"""
        types = place_data.get("types", [])
        rating = place_data.get("rating", 0.0)
        ratings_total = place_data.get("ratings_total", 0)
        price_level = place_data.get("price_level", 0)
        opening_hours = place_data.get("opening_hours", {})
        address = place_data.get("address", "")
        
        # å ´æ‰€ã®èª¬æ˜éƒ¨åˆ†ã‚’æ§‹ç¯‰
        description_parts = []
        
        # å ´æ‰€ã®ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãèª¬æ˜
        type_descriptions = {
            "restaurant": "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³",
            "cafe": "ã‚«ãƒ•ã‚§",
            "museum": "åšç‰©é¤¨",
            "park": "å…¬åœ’",
            "temple": "å¯ºé™¢",
            "shrine": "ç¥ç¤¾",
            "shopping_mall": "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«",
            "tourist_attraction": "è¦³å…‰ã‚¹ãƒãƒƒãƒˆ",
            "amusement_park": "éŠåœ’åœ°",
            "art_gallery": "ç¾è¡“é¤¨",
            "aquarium": "æ°´æ—é¤¨",
            "zoo": "å‹•ç‰©åœ’",
            "spa": "ã‚¹ãƒ‘",
            "night_club": "ãƒŠã‚¤ãƒˆã‚¯ãƒ©ãƒ–",
            "bar": "ãƒãƒ¼",
            "bakery": "ãƒ™ãƒ¼ã‚«ãƒªãƒ¼",
            "book_store": "æ›¸åº—",
            "clothing_store": "è¡£æ–™å“åº—",
            "department_store": "ãƒ‡ãƒ‘ãƒ¼ãƒˆ",
            "electronics_store": "é›»å™¨åº—",
            "gym": "ã‚¸ãƒ ",
            "hair_care": "ç¾å®¹é™¢",
            "hospital": "ç—…é™¢",
            "library": "å›³æ›¸é¤¨",
            "movie_theater": "æ˜ ç”»é¤¨",
            "pharmacy": "è–¬å±€",
            "school": "å­¦æ ¡",
            "supermarket": "ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆ",
            "train_station": "é§…",
            "subway_station": "åœ°ä¸‹é‰„é§…"
        }
        
        # ãƒ¡ã‚¤ãƒ³ã®ã‚¿ã‚¤ãƒ—ã‚’ç‰¹å®š
        main_type = None
        for place_type in types:
            if place_type in type_descriptions:
                main_type = type_descriptions[place_type]
                break
        
        if main_type:
            description_parts.append(main_type)
        
        # ä¾¡æ ¼å¸¯ã®æƒ…å ±ï¼ˆãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã‚„ã‚«ãƒ•ã‚§ãªã©ã®å ´åˆï¼‰
        if price_level > 0 and main_type in ["ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "ã‚«ãƒ•ã‚§", "ãƒãƒ¼"]:
            price_descriptions = {
                1: "ãƒªãƒ¼ã‚ºãƒŠãƒ–ãƒ«ãªä¾¡æ ¼å¸¯",
                2: "æ‰‹é ƒãªä¾¡æ ¼å¸¯",
                3: "ã‚„ã‚„é«˜ç´š",
                4: "é«˜ç´š"
            }
            if price_level in price_descriptions:
                description_parts.append(price_descriptions[price_level])
        
        # è©•ä¾¡ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®æƒ…å ±
        if rating > 0 and ratings_total > 0:
            if ratings_total >= 1000:
                description_parts.append(f"è©•ä¾¡{rating:.1f}ï¼ˆ{ratings_total}ä»¶ä»¥ä¸Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰")
            elif ratings_total >= 100:
                description_parts.append(f"è©•ä¾¡{rating:.1f}ï¼ˆ{ratings_total}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰")
            else:
                description_parts.append(f"è©•ä¾¡{rating:.1f}")
        
        # å–¶æ¥­æ™‚é–“ã®æƒ…å ±
        if opening_hours:
            if opening_hours.get("open_now") is True:
                description_parts.append("ç¾åœ¨å–¶æ¥­ä¸­")
            elif opening_hours.get("open_now") is False:
                description_parts.append("ç¾åœ¨å–¶æ¥­æ™‚é–“å¤–")
            
            # å–¶æ¥­æ™‚é–“ã®è©³ç´°ï¼ˆã‚ã‚Œã°ï¼‰
            weekday_text = opening_hours.get("weekday_text", [])
            if weekday_text and len(weekday_text) > 0:
                # ä»Šæ—¥ã®å–¶æ¥­æ™‚é–“ã‚’æŠ½å‡ºï¼ˆæœ€åˆã®1è¡Œç›®ï¼‰
                today_hours = weekday_text[0] if isinstance(weekday_text[0], str) else ""
                if "24 æ™‚é–“å–¶æ¥­" in today_hours or "24æ™‚é–“" in today_hours:
                    description_parts.append("24æ™‚é–“å–¶æ¥­")
        
        # ã‚¨ãƒªã‚¢æƒ…å ±ï¼ˆä½æ‰€ã‹ã‚‰æŠ½å‡ºï¼‰
        if address:
            # æ—¥æœ¬ã®ä½æ‰€ã‹ã‚‰åŒºãƒ»å¸‚ã‚’æŠ½å‡º
            import re
            area_match = re.search(r'([^éƒ½é“åºœçœŒ]+[å¸‚åŒºç”ºæ‘])', address)
            if area_match:
                area = area_match.group(1)
                description_parts.append(f"{area}ã‚¨ãƒªã‚¢")
        
        # ç‰¹æ®Šãªæ–½è¨­ã‚¿ã‚¤ãƒ—ã®è¿½åŠ æƒ…å ±
        special_features = []
        for place_type in types:
            if place_type == "point_of_interest":
                special_features.append("åæ‰€")
            elif place_type == "natural_feature":
                special_features.append("è‡ªç„¶ã‚¹ãƒãƒƒãƒˆ")
            elif place_type == "establishment":
                continue  # ä¸€èˆ¬çš„ã™ãã‚‹ã®ã§ç„¡è¦–
            elif place_type == "food" and main_type not in ["ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "ã‚«ãƒ•ã‚§"]:
                special_features.append("é£²é£Ÿåº—")
        
        if special_features:
            description_parts.extend(special_features[:2])  # æœ€å¤§2ã¤ã¾ã§
        
        # æ–‡ç« ã‚’çµ„ã¿ç«‹ã¦
        if description_parts:
            # æœ€åˆã®è¦ç´ ï¼ˆå ´æ‰€ã®ã‚¿ã‚¤ãƒ—ï¼‰ã‚’é™¤ã„ã¦ã€æ®‹ã‚Šã‚’ã€Œã€ã€ã§çµåˆ
            if len(description_parts) == 1:
                return description_parts[0] + "ã§ã™ã€‚"
            else:
                main_desc = description_parts[0]
                sub_desc = "ã€".join(description_parts[1:])
                return f"{main_desc}ã§ã™ã€‚{sub_desc}ã€‚"
        else:
            return "è©³ç´°æƒ…å ±ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    def _convert_to_spot_schema_fast(
        self, place_data: Dict[str, Any], index: int
    ) -> Dict[str, Any]:
        """ê³ ì† ìŠ¤íŒŸ ìŠ¤í‚¤ë§ˆ ë³€í™˜"""
        lat = place_data.get("lat", 41.3851)
        lng = place_data.get("lng", 2.1734)

        # Google Mapã«æŠ•ç¨¿ã•ã‚ŒãŸå†™çœŸã®URLã‚’å–å¾—ï¼ˆæœ€åˆã®1æšï¼‰
        photos = place_data.get("photos", [])
        google_map_image_url = photos[0] if photos else None

        return {
            "spot_id": place_data.get("place_id", f"spot_{index}"),
            "longitude": lng,
            "latitude": lat,
            "recommendation_reason": self._generate_recommendation_reason(place_data),
            "details": {
                "name": place_data.get("name", f"ì¥ì†Œ_{index}"),
                "congestion": self._generate_realistic_congestion(
                    place_data, index
                ),  # í˜„ì‹¤ì ì¸ í˜¼ì¡ë„
                "business_hours": {
                    day: {"open_time": "09:00:00", "close_time": "18:00:00"}
                    for day in [
                        "MONDAY",
                        "TUESDAY",
                        "WEDNESDAY",
                        "THURSDAY",
                        "FRIDAY",
                        "SATURDAY",
                        "SUNDAY",
                        "HOLIDAY",
                    ]
                },
                "price": place_data.get("price_level", 2) * 1000,
            },
            "google_map_image_url": google_map_image_url,
            "website_url": place_data.get("website", None),
            "selected": False,
            "similarity_score": place_data.get(
                "similarity_score", None
            ),  # similarity_score ì¶”ê°€
        }

    async def get_recommendations(
        self, pre_info: PreInfo, chat_keywords: Optional[List[str]] = None
    ) -> Dict:
        """
        Get spot recommendations based on pre_info.
        If chat_keywords are provided, they are used instead of generating new ones.
        """
        start_time = time.time()
        logger.info("ğŸš€ SUPER ìµœì í™” ëª¨ë“œ ì‹œì‘!")

        if chat_keywords:
            logger.info(f"ğŸ’¬ Using keywords from chat: {chat_keywords}")
            tasks = [
                asyncio.sleep(
                    0, result=chat_keywords
                ),  # immediately completed coroutine
                self.llm_service.generate_llm_weights(pre_info),
                self.vector_search_service.get_similar_spots_by_pre_info(pre_info),
            ]
        else:
            logger.info("ğŸ”¥ 3ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...")
            tasks = [
                self._generate_llm_keywords(pre_info),
                self.llm_service.generate_llm_weights(pre_info),
                self.vector_search_service.get_similar_spots_by_pre_info(pre_info),
            ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for result in results:
            if isinstance(result, Exception):
                # ì˜ˆì™¸ ì²˜ë¦¬ ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                logger.error(f"ì‘ì—… ì‹¤íŒ¨: {result}")

        # ì´ì „ ì½”ë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ìœ ì§€
        # ...

        # ì„ì‹œ fallback: ê¸°ì¡´ recommend_spots_from_pre_info ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        # ë§Œì•½ ìƒë‹¨ ìµœì í™” ë¡œì§ì´ ì•„ì§ ì™„ì„±ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ì•ˆì „í•˜ê²Œ ì´ì „ êµ¬í˜„ì„ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ë°˜í™˜
        logger.info("ğŸ”„ Falling back to recommend_spots_from_pre_info pipeline")
        return await self.recommend_spots_from_pre_info(pre_info)

    async def _generate_llm_keywords(self, pre_info: PreInfo) -> List[str]:
        """Alias for backward-compatibility with older code paths."""
        return await self._generate_keywords_optimized(pre_info)
