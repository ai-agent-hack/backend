import json
import os
from typing import List, Dict, Any, Tuple
from google.oauth2 import service_account
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig

from app.models.pre_info import PreInfo
from app.core.config import settings


class LLMService:
    """
    LLM ã‚µãƒ¼ãƒ“ã‚¹ - Vertex AI Gemini ã‚’ä½¿ç”¨
    """

    def __init__(self):
        self.model = None
        self._initialize_vertex_ai()

    def _initialize_vertex_ai(self):
        """Vertex AI åˆæœŸåŒ–"""
        try:
            project_id = os.getenv("GOOGLE_PROJECT_ID") or os.getenv(
                "GOOGLE_CLOUD_PROJECT"
            )
            if not project_id:
                raise Exception("GOOGLE_PROJECT_IDç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

            # èªè¨¼æƒ…å ±ã®å–å¾—
            credentials = self._get_vertex_credentials()

            # Vertex AI åˆæœŸåŒ–
            if credentials:
                vertexai.init(
                    project=project_id, location="us-central1", credentials=credentials
                )
            else:
                vertexai.init(project=project_id, location="us-central1")

            # Gemini ãƒ¢ãƒ‡ãƒ«è¨­å®š
            self.model = GenerativeModel("gemini-2.0-flash")
            print("âœ… Vertex AI Gemini ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            print(f"âŒ Vertex AI åˆæœŸåŒ–å¤±æ•—: {str(e)}")
            self.model = None

    def _get_vertex_credentials(self):
        """Google Cloud èªè¨¼æƒ…å ±å–å¾—"""
        try:
            service_account_data = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if service_account_data:
                # JSONæ–‡å­—åˆ—ã®å ´åˆ
                if service_account_data.strip().startswith("{"):
                    credentials_info = json.loads(service_account_data)
                    credentials = service_account.Credentials.from_service_account_info(
                        credentials_info
                    )
                    return credentials
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
                elif os.path.exists(service_account_data):
                    credentials = service_account.Credentials.from_service_account_file(
                        service_account_data
                    )
                    return credentials
            return None
        except Exception as e:
            print(f"âŒ èªè¨¼æƒ…å ±ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")
            return None

    async def generate_keywords_and_weights(
        self, pre_info: PreInfo
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        Step 3-1: pre_infoã‚’åŸºã«æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨åˆæœŸé‡ã¿ã‚’ç”Ÿæˆ

        Args:
            pre_info: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ—…è¡Œäº‹å‰æƒ…å ±

        Returns:
            tuple: (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ, é‡ã¿è¾æ›¸)
        """
        if not self.model:
            print("âš ï¸ Vertex AI ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ä½¿ç”¨")
            return self._get_fallback_keywords_and_weights(pre_info)

        try:
            prompt = self._create_keyword_generation_prompt(pre_info)

            generation_config = GenerationConfig(
                temperature=0.7,  # å‰µé€ æ€§ã¨ä¸€è²«æ€§ã®ãƒãƒ©ãƒ³ã‚¹
                top_p=0.9,
                max_output_tokens=1024,
                response_mime_type="application/json",  # JSONå½¢å¼ã§å¿œç­”è¦æ±‚
            )

            print(
                f"ğŸ¤– LLMã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆè¦è«‹ä¸­... (åœ°åŸŸ: {pre_info.region}, äºˆç®—: {pre_info.budget:,}å††, é›°å›²æ°—: {pre_info.atmosphere})"
            )
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config,
            )

            # JSONå¿œç­”ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)
            keywords = result.get("keywords", [])
            weights = result.get("weights", {})

            # é‡ã¿å€¤ã‚’floatã«å¤‰æ› (LLMãŒæ–‡å­—åˆ—ã§è¿”ã™å¯èƒ½æ€§)
            converted_weights = {}
            for key, value in weights.items():
                try:
                    converted_weights[key] = float(value)
                except (ValueError, TypeError):
                    converted_weights[key] = 0.1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

            # æœ‰åŠ¹æ€§æ¤œè¨¼
            if not keywords or not converted_weights:
                raise Exception("LLMå¿œç­”ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¾ãŸã¯é‡ã¿ãŒã‚ã‚Šã¾ã›ã‚“")

            print(f"âœ… LLMã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”ŸæˆæˆåŠŸ: {keywords}")
            print(f"âœ… LLMé‡ã¿ç”Ÿæˆ: {converted_weights}")
            return keywords, converted_weights

        except Exception as e:
            print(f"âŒ LLMã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆå¤±æ•—: {str(e)}")
            return self._get_fallback_keywords_and_weights(pre_info)

    def _create_keyword_generation_prompt(self, pre_info: PreInfo) -> str:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®æ—…è¡Œæƒ…å ±ã‚’åˆ†æã—ã¦ã€ã‚¹ãƒãƒƒãƒˆæ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ¨è–¦é‡ã¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**æ—…è¡Œæƒ…å ±:**
- åœ°åŸŸ: {pre_info.region}  
- æ—…è¡ŒæœŸé–“: {pre_info.start_date.strftime('%Y-%m-%d')} ~ {pre_info.end_date.strftime('%Y-%m-%d')}
- äºˆç®—: {pre_info.budget:,}å††
- é›°å›²æ°—/å¥½ã¿: {pre_info.atmosphere}

**é‡è¦æŒ‡ç¤º:**
1. **é›°å›²æ°—/å¥½ã¿**ã‚’æœ€å„ªå…ˆã«è€ƒæ…®ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„
2. äºˆç®—ã¨åœ°åŸŸç‰¹æ€§ã‚’åæ˜ ã—ãŸå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠ
3. é›°å›²æ°—ã«åˆã£ãŸé‡ã¿èª¿æ•´å¿…é ˆ

**è¦æ±‚äº‹é …:**
1. æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3-5å€‹ã‚’ç”Ÿæˆ:
   - åœ°åŸŸå + é›°å›²æ°—é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ„ã¿åˆã‚ã›
   - å…·ä½“çš„ã§æ¤œç´¢å¯èƒ½ãªå½¢å¼
   - é›°å›²æ°—ã‚’åæ˜ ã—ãŸç‰¹æ€§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«ã‚€
   
2. æ¨è–¦é‡ã¿ã‚’0-1ã®å€¤ã§è¨­å®š:
   - price: ä¾¡æ ¼é‡è¦åº¦ (äºˆç®—ãŒå°‘ãªã„ã»ã©é«˜ã)
   - rating: è©•ç‚¹é‡è¦åº¦ 
   - congestion: æ··é›‘åº¦é‡è¦åº¦ (é™ã‹ãªé›°å›²æ°—ãªã‚‰é«˜ã)
   - similarity: æ„å‘³çš„é¡ä¼¼åº¦é‡è¦åº¦ (é›°å›²æ°—ãƒãƒƒãƒåº¦)

**é›°å›²æ°—åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆä¾‹:**
- "é™ã‹/å¹³å’Œ" â†’ "é™ã‹ãªã‚«ãƒ•ã‚§", "é–‘é™ãªå…¬åœ’", "å¹³å’Œãªåº­åœ’"
- "æ´»æ°—/è³‘ã‚„ã‹" â†’ "äººæ°—ã‚°ãƒ«ãƒ¡", "ç¹è¯è¡—", "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°è¡—" 
- "ãƒ­ãƒãƒ³ãƒãƒƒã‚¯" â†’ "ãƒ­ãƒãƒ³ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "å¤œæ™¯ã‚¹ãƒãƒƒãƒˆ", "ã‚«ãƒƒãƒ—ãƒ«ã‚«ãƒ•ã‚§"
- "å®¶æ—å‘ã‘" â†’ "ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "å­ä¾›ã®éŠã³å ´", "ä½“é¨“æ–½è¨­"

**å¿œç­”å½¢å¼ (JSON):**
{{
  "keywords": ["åœ°åŸŸå é›°å›²æ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "åœ°åŸŸå é›°å›²æ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "åœ°åŸŸå ç‰¹æ€§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
  "weights": {{
    "price": 0.3,
    "rating": 0.4,
    "congestion": 0.2,
    "similarity": 0.1
  }},
  "atmosphere_analysis": "é›°å›²æ°—åˆ†æãŠã‚ˆã³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠç†ç”±"
}}

é›°å›²æ°— '{pre_info.atmosphere}' ã‚’æ ¸å¿ƒã¨ã—ã¦ {pre_info.region} åœ°åŸŸã®é©åˆ‡ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨é‡ã¿ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚
"""
        return prompt

    def _get_fallback_keywords_and_weights(
        self, pre_info: PreInfo
    ) -> Tuple[List[str], Dict[str, float]]:
        """LLMå¤±æ•—æ™‚ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨é‡ã¿"""
        print(
            f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ä½¿ç”¨ - åœ°åŸŸ: {pre_info.region}, äºˆç®—: {pre_info.budget:,}å††"
        )

        # åœ°åŸŸãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        region_keywords = {
            "ã‚½ã‚¦ãƒ«": ["ã‚½ã‚¦ãƒ« ã‚«ãƒ•ã‚§", "æ±Ÿå— ã‚°ãƒ«ãƒ¡", "æ¼¢æ±Ÿ å…¬åœ’"],
            "é‡œå±±": ["é‡œå±± æµ·å²¸", "åºƒå®‰é‡Œ", "ç”˜å·æ–‡åŒ–æ‘"],
            "æ¸ˆå·": ["æ¸ˆå· è‡ªç„¶", "æ¼¢æ‹å±±", "æ¸ˆå· ã‚«ãƒ•ã‚§"],
            "æ±äº¬": ["æ±äº¬ ã‚«ãƒ•ã‚§", "æ¸‹è°· ã‚°ãƒ«ãƒ¡", "æµ…è‰ è¦³å…‰"],
            "å¤§é˜ª": ["å¤§é˜ª ã‚°ãƒ«ãƒ¡", "é“é “å €", "å¤§é˜ªåŸ"],
            "äº¬éƒ½": ["äº¬éƒ½ å¯ºé™¢", "åµå±±", "æ¸…æ°´å¯º"],
        }

        # äºˆç®—ãƒ™ãƒ¼ã‚¹ã®é‡ã¿èª¿æ•´
        if pre_info.budget < 50000:
            weights = {
                "price": 0.5,
                "rating": 0.3,
                "congestion": 0.1,
                "similarity": 0.1,
            }
        elif pre_info.budget < 100000:
            weights = {
                "price": 0.3,
                "rating": 0.4,
                "congestion": 0.2,
                "similarity": 0.1,
            }
        else:
            weights = {
                "price": 0.2,
                "rating": 0.4,
                "congestion": 0.3,
                "similarity": 0.1,
            }

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠ
        keywords = region_keywords.get(
            pre_info.region,
            [
                f"{pre_info.region} è¦³å…‰åœ°",
                f"{pre_info.region} ã‚°ãƒ«ãƒ¡",
                f"{pre_info.region} ã‚«ãƒ•ã‚§",
            ],
        )

        print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
        print(f"âš–ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é‡ã¿: {weights}")
        return keywords, weights

    async def rerank_and_adjust_weights(
        self,
        candidates: List[Dict[str, Any]],
        weights: Dict[str, float],
        pre_info: PreInfo,
        target_count: int = 40,
    ) -> Tuple[List[Dict[str, Any]], Dict[str, float]]:
        """
        ã‚¹ãƒ†ãƒƒãƒ— 3-6: LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚° + é‡ã¿èª¿æ•´ï¼ˆ80å€‹ â†’ 40å€‹ï¼‰

        Args:
            candidates: 80å€‹ã®å€™è£œå ´æ‰€ãƒªã‚¹ãƒˆ
            weights: ç¾åœ¨ã®é‡ã¿
            pre_info: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ—…è¡Œæƒ…å ±
            target_count: é¸åˆ¥ã™ã‚‹å ´æ‰€æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ40å€‹ï¼‰

        Returns:
            tuple: (å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸ40å€‹ã®å ´æ‰€, èª¿æ•´ã•ã‚ŒãŸé‡ã¿)
        """
        if not self.model:
            print("âš ï¸ Vertex AI ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            return self._fallback_reranking(candidates, weights, target_count)

        try:
            print(f"ğŸ¤– LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°é–‹å§‹: {len(candidates)}å€‹ â†’ {target_count}å€‹")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            prompt = self._create_rerank_prompt(
                candidates, weights, pre_info, target_count
            )

            generation_config = GenerationConfig(
                temperature=0.3,  # ä¸€è²«æ€§é‡è¦–
                top_p=0.8,
                max_output_tokens=2048,
                response_mime_type="application/json",
            )

            response = self.model.generate_content(
                prompt,
                generation_config=generation_config,
            )

            # JSONå¿œç­”ãƒ‘ãƒ¼ã‚¹
            result = json.loads(response.text)

            # é¸åˆ¥ã•ã‚ŒãŸå ´æ‰€IDãƒªã‚¹ãƒˆ
            selected_place_ids = result.get("selected_place_ids", [])
            adjusted_weights = result.get("adjusted_weights", weights)
            reasoning = result.get("reasoning", "å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Œäº†")

            # é‡ã¿ã‚’floatã«å¤‰æ›
            converted_weights = {}
            for key, value in adjusted_weights.items():
                try:
                    converted_weights[key] = float(value)
                except (ValueError, TypeError):
                    converted_weights[key] = weights.get(key, 0.25)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨

            # é¸åˆ¥ã•ã‚ŒãŸå ´æ‰€ã‚’é †ç•ªã«ä¸¦ã¹æ›¿ãˆ
            reranked_places = []
            candidate_map = {
                place.get("place_id", place.get("name", "")): place
                for place in candidates
            }

            for place_id in selected_place_ids:
                if place_id in candidate_map:
                    place = candidate_map[place_id].copy()
                    place["llm_rank"] = len(reranked_places) + 1
                    place["llm_reasoning"] = reasoning
                    reranked_places.append(place)

                if len(reranked_places) >= target_count:
                    break

            # ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯æ®‹ã‚Šã®å€™è£œã‹ã‚‰è£œå®Œ
            if len(reranked_places) < target_count:
                remaining_count = target_count - len(reranked_places)
                used_ids = {
                    p.get("place_id", p.get("name", "")) for p in reranked_places
                }

                for place in candidates:
                    place_id = place.get("place_id", place.get("name", ""))
                    if place_id not in used_ids:
                        place_copy = place.copy()
                        place_copy["llm_rank"] = len(reranked_places) + 1
                        place_copy["llm_reasoning"] = "è£œå®Œé¸æŠ"
                        reranked_places.append(place_copy)

                        if len(reranked_places) >= target_count:
                            break

            print(f"âœ… LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Œäº†: {len(reranked_places)}å€‹é¸åˆ¥")
            print(f"ğŸ¯ èª¿æ•´ã•ã‚ŒãŸé‡ã¿: {converted_weights}")
            print(f"ğŸ’­ LLMåˆ¤æ–­: {reasoning[:100]}...")

            return reranked_places, converted_weights

        except Exception as e:
            print(f"âŒ LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤±æ•—: {str(e)}")
            return self._fallback_reranking(candidates, weights, target_count)

    def _create_rerank_prompt(
        self,
        candidates: List[Dict[str, Any]],
        weights: Dict[str, float],
        pre_info: PreInfo,
        target_count: int,
    ) -> str:
        """å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""

        # å€™è£œå ´æ‰€ã‚’è¦ç´„å½¢å¼ã«å¤‰æ›
        candidate_summaries = []
        for i, place in enumerate(candidates[:80]):  # æœ€å¤§80å€‹ã¾ã§
            summary = {
                "id": place.get("place_id", f"place_{i}"),
                "name": place.get("name", f"å ´æ‰€_{i}"),
                "rating": place.get("rating", 0.0),
                "price_level": place.get("price_level", 2),
                "address": place.get("address", "ä½æ‰€æƒ…å ±ãªã—")[:50],  # ä½æ‰€ã®é•·ã•åˆ¶é™
                "types": place.get("types", [])[:3],  # ã‚¿ã‚¤ãƒ—æ•°åˆ¶é™
                "similarity_score": place.get("similarity_score", 0.5),
            }
            candidate_summaries.append(summary)

        prompt = f"""
æ¬¡ã¯æ—…è¡Œæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®å ´æ‰€å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæ¥­ã§ã™ã€‚80å€‹ã®å€™è£œã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©ãª{target_count}å€‹ã‚’é¸åˆ¥ã—ã¦ãã ã•ã„ã€‚

**ãƒ¦ãƒ¼ã‚¶ãƒ¼æ—…è¡Œæƒ…å ±:**
- åœ°åŸŸ: {pre_info.region}
- äºˆç®—: {pre_info.budget:,}å††
- äººæ•°: {pre_info.participants_count}å
- é›°å›²æ°—ã®å¥½ã¿: {pre_info.atmosphere}
- æœŸé–“: {pre_info.start_date} ~ {pre_info.end_date}

**ç¾åœ¨ã®é‡ã¿:**
{json.dumps(weights, indent=2, ensure_ascii=False)}

**å€™è£œå ´æ‰€ï¼ˆ80å€‹ï¼‰:**
{json.dumps(candidate_summaries, indent=2, ensure_ascii=False)}

**ä½œæ¥­è¦ä»¶:**

1. **ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®äºˆç®—ã€é›°å›²æ°—ã€äººæ•°ã‚’è€ƒæ…®ã—ã¦ä¸é©åˆãªå ´æ‰€ã‚’é™¤å¤–
   - äºˆç®—è¶…éã®å ´æ‰€ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (price_level 4 = é«˜ç´š, 3 = ä¸­ç´š, 2 = æ™®é€š, 1 = å®‰ã„)
   - é›°å›²æ°—ã«åˆã‚ãªã„å ´æ‰€ã‚’é™¤å¤–
   - ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã«ä¸é©åˆãªå ´æ‰€ã‚’é™¤å¤–

2. **å¤šæ§˜æ€§ã®ä¿è¨¼**: ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒãƒ©ãƒ³ã‚¹ã®ç¶­æŒ
   - ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã€è¦³å…‰åœ°ã€æ–‡åŒ–æ–½è¨­ã€ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãªã©å¤šæ§˜ãªã‚¿ã‚¤ãƒ—ã‚’å«ã‚€
   - åŒä¸€åœ°åŸŸã¸ã®é›†ä¸­ã‚’é˜²æ­¢

3. **å“è³ªå„ªå…ˆé †ä½**: 
   - è©•ç‚¹4.0ä»¥ä¸Šã‚’å„ªå…ˆé¸æŠ
   - ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãŒå¤šã„ä¿¡é ¼ã§ãã‚‹å ´æ‰€ã‚’å„ªå…ˆ
   - ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’è€ƒæ…®

4. **é‡ã¿èª¿æ•´**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦é‡ã¿ã‚’å¾®èª¿æ•´
   - äºˆç®—åˆ¶ç´„ãŒå¼·ã„å ´åˆ â†’ priceé‡ã¿ã‚’å¢—åŠ 
   - é›°å›²æ°—é‡è¦– â†’ similarity, congestioné‡ã¿ã‚’å¢—åŠ 
   - å®‰å…¨æ€§é‡è¦– â†’ ratingé‡ã¿ã‚’å¢—åŠ 

**å¿œç­”å½¢å¼ (JSON):**
```json
{{
  "selected_place_ids": ["place_id_1", "place_id_2", ..., "place_id_{target_count}"],
  "adjusted_weights": {{
    "price": 0.35,
    "rating": 0.35,
    "congestion": 0.20,
    "similarity": 0.10
  }},
  "reasoning": "é¸åˆ¥åŸºæº–ã¨é‡ã¿èª¿æ•´ã®ç†ç”±ã‚’2-3æ–‡ã§èª¬æ˜",
  "category_distribution": {{
    "restaurant": 12,
    "tourist_attraction": 8,
    "shopping": 5,
    "cultural": 6,
    "other": 9
  }}
}}
```

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®'{pre_info.atmosphere}'ã®é›°å›²æ°—ã¨äºˆç®—{pre_info.budget:,}å††ã‚’æ ¸å¿ƒåŸºæº–ã¨ã—ã¦æœ€é©ãª{target_count}å€‹ã‚’é¸åˆ¥ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt

    def _fallback_reranking(
        self,
        candidates: List[Dict[str, Any]],
        weights: Dict[str, float],
        target_count: int,
    ) -> Tuple[List[Dict[str, Any]], Dict[str, float]]:
        """LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯"""
        print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(candidates)}å€‹ â†’ {target_count}å€‹")

        # è©•ç‚¹åŸºæº–ã§ã‚½ãƒ¼ãƒˆ
        sorted_candidates = sorted(
            candidates,
            key=lambda x: (
                x.get("rating", 0.0) * 0.6 + x.get("similarity_score", 0.0) * 0.4
            ),
            reverse=True,
        )

        # ä¸Šä½target_countå€‹ã‚’é¸æŠ
        selected = sorted_candidates[:target_count]

        # é‡ã¿ã‚’å°å¹…èª¿æ•´ï¼ˆratingä¸­å¿ƒã«ï¼‰
        adjusted_weights = weights.copy()
        adjusted_weights["rating"] = min(0.5, adjusted_weights.get("rating", 0.4) + 0.1)

        print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Œäº†: {len(selected)}å€‹")
        return selected, adjusted_weights
